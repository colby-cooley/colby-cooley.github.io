[
  {
    "objectID": "traffic_stops.html",
    "href": "traffic_stops.html",
    "title": "Traffic Stops",
    "section": "",
    "text": "Traffic stop data offer important insights into how policing practices vary across time and demographic groups. In this project, I investigate whether search behavior varies by time of day and driver race across three distinct jurisdictions in the Stanford Open Policing Project database: Arizona Statewide, Oakland (CA), and Saint Paul (MN).\n\ncon_traffic &lt;- DBI::dbConnect(\n\n  RMariaDB::MariaDB(),\n\n  dbname = \"traffic\",\n\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n\n)\n\nTo address this question, I will attempt to combine three separate SQL tables into a unified dataset. I will then try to visualize the resulting search patterns to explore whether certain racial groups experience higher search rates during specific hours of the day.\nThe following table combines the data from all three tables into one, big table. It groups the data by the hour of the day and by the race of the driver. It also gives the number of stops, number of searches, and percentage of stops that were searches for each of these groups.\n\nSELECT\n  hour,\n  subject_race,\n  n_stops,\n  n_searched,\n  ROUND(100.0 * n_searched / n_stops, 2) AS pct_searched\nFROM (\n    SELECT\n      CONVERT(TIME_FORMAT(time, '%H'), UNSIGNED) AS hour,\n      subject_race,\n      COUNT(*) AS n_stops,\n      SUM(search_conducted) AS n_searched\n    FROM (\n        SELECT time, subject_race, search_conducted\n        FROM az_statewide_2020_04_01\n\n        UNION ALL\n\n        SELECT time, subject_race, search_conducted\n        FROM ca_oakland_2020_04_01\n\n        UNION ALL\n\n        SELECT time, subject_race, search_conducted\n        FROM mn_saint_paul_2020_04_01\n    ) AS combined\n    WHERE subject_race IS NOT NULL\n      AND TIME_FORMAT(time, '%H') IS NOT NULL\n    GROUP BY hour, subject_race\n    HAVING COUNT(*) &gt; 1000\n) AS hourly\nORDER BY hour, subject_race\n\n\nhourly\n\n    hour           subject_race n_stops n_searched pct_searched\n1      0 asian/pacific islander    6385        570         8.93\n2      0                  black   27994       4821        17.22\n3      0               hispanic   16906       2715        16.06\n4      0                  other    2317        387        16.70\n5      0                  white   41049       4055         9.88\n6      1 asian/pacific islander    4250        364         8.56\n7      1                  black   19170       3481        18.16\n8      1               hispanic   14072       2628        18.68\n9      1                  other    1444        315        21.81\n10     1                  white   28649       3551        12.39\n11     2 asian/pacific islander    2571        276        10.74\n12     2                  black   13260       2701        20.37\n13     2               hispanic   11386       2818        24.75\n14     2                  other    1051        389        37.01\n15     2                  white   19285       3152        16.34\n16     3 asian/pacific islander    1719        195        11.34\n17     3                  black    7927       1684        21.24\n18     3               hispanic    7866       1635        20.79\n19     3                  white   12840       1745        13.59\n20     4 asian/pacific islander    1217         97         7.97\n21     4                  black    5032        958        19.04\n22     4               hispanic    6912       1034        14.96\n23     4                  white   11533       1133         9.82\n24     5 asian/pacific islander    1601         76         4.75\n25     5                  black    6159        741        12.03\n26     5               hispanic   16769       1590         9.48\n27     5                  other    1432        227        15.85\n28     5                  white   33432       1334         3.99\n29     6 asian/pacific islander    2758         76         2.76\n30     6                  black   10886        898         8.25\n31     6               hispanic   38226       2667         6.98\n32     6                  other    4194        352         8.39\n33     6                  white   74716       2308         3.09\n34     7 asian/pacific islander    5521        150         2.72\n35     7                  black   17555       1532         8.73\n36     7               hispanic   56336       4036         7.16\n37     7                  other    7859        468         5.95\n38     7                unknown    1357         50         3.68\n39     7                  white  124248       3529         2.84\n40     8 asian/pacific islander    7507        211         2.81\n41     8                  black   21580       1869         8.66\n42     8               hispanic   63703       4323         6.79\n43     8                  other    9617        680         7.07\n44     8                unknown    1543         63         4.08\n45     8                  white  143734       4124         2.87\n46     9 asian/pacific islander    7536        202         2.68\n47     9                  black   19891       2039        10.25\n48     9               hispanic   59863       4185         6.99\n49     9                  other    9860        773         7.84\n50     9                unknown    1380         42         3.04\n51     9                  white  133696       3973         2.97\n52    10 asian/pacific islander    7779        218         2.80\n53    10                  black   20147       2227        11.05\n54    10               hispanic   57611       3976         6.90\n55    10                  other   10284        791         7.69\n56    10                unknown    1291         40         3.10\n57    10                  white  132448       4128         3.12\n58    11 asian/pacific islander    6721        196         2.92\n59    11                  black   16963       2037        12.01\n60    11               hispanic   47224       3504         7.42\n61    11                  other    8931        779         8.72\n62    11                unknown    1102         42         3.81\n63    11                  white  113014       3605         3.19\n64    12 asian/pacific islander    6676        229         3.43\n65    12                  black   18316       2149        11.73\n66    12               hispanic   52933       3823         7.22\n67    12                  other    9751        835         8.56\n68    12                unknown    1273         54         4.24\n69    12                  white  126468       4341         3.43\n70    13 asian/pacific islander    7365        223         3.03\n71    13                  black   21147       2747        12.99\n72    13               hispanic   62155       4626         7.44\n73    13                  other   11926       1159         9.72\n74    13                unknown    1531         70         4.57\n75    13                  white  143444       4816         3.36\n76    14 asian/pacific islander    7897        236         2.99\n77    14                  black   23185       3582        15.45\n78    14               hispanic   70806       5859         8.27\n79    14                  other   12548       1289        10.27\n80    14                unknown    1608         71         4.42\n81    14                  white  156751       5690         3.63\n82    15 asian/pacific islander    7194        279         3.88\n83    15                  black   22490       4147        18.44\n84    15               hispanic   66816       6449         9.65\n85    15                  other   12741       1461        11.47\n86    15                unknown    1536         81         5.27\n87    15                  white  145329       6001         4.13\n88    16 asian/pacific islander    7582        306         4.04\n89    16                  black   24024       4463        18.58\n90    16               hispanic   63707       6231         9.78\n91    16                  other   12567       1265        10.07\n92    16                unknown    1537         50         3.25\n93    16                  white  142870       5966         4.18\n94    17 asian/pacific islander    9036        373         4.13\n95    17                  black   28181       5031        17.85\n96    17               hispanic   59820       5641         9.43\n97    17                  other   12855       1282         9.97\n98    17                unknown    1398         51         3.65\n99    17                  white  142083       6480         4.56\n100   18 asian/pacific islander    7790        393         5.04\n101   18                  black   25261       4611        18.25\n102   18               hispanic   49482       4996        10.10\n103   18                  other   10163        955         9.40\n104   18                unknown    1116         51         4.57\n105   18                  white  119589       5530         4.62\n106   19 asian/pacific islander    7051        369         5.23\n107   19                  black   23903       4271        17.87\n108   19               hispanic   41610       4078         9.80\n109   19                  other    9049        908        10.03\n110   19                  white   99311       4762         4.80\n111   20 asian/pacific islander    7355        318         4.32\n112   20                  black   24939       3836        15.38\n113   20               hispanic   44177       4327         9.79\n114   20                  other    8755        988        11.28\n115   20                unknown    1037         47         4.53\n116   20                  white  105488       5080         4.82\n117   21 asian/pacific islander    7882        329         4.17\n118   21                  black   26847       3585        13.35\n119   21               hispanic   46507       4884        10.50\n120   21                  other    8366       1040        12.43\n121   21                unknown    1092         65         5.95\n122   21                  white  108378       5614         5.18\n123   22 asian/pacific islander    7797        392         5.03\n124   22                  black   29762       4305        14.46\n125   22               hispanic   40249       4404        10.94\n126   22                  other    6240        798        12.79\n127   22                  white   91427       5469         5.98\n128   23 asian/pacific islander    8575        521         6.08\n129   23                  black   35773       5410        15.12\n130   23               hispanic   30325       3941        13.00\n131   23                  other    4029        573        14.22\n132   23                  white   70334       5283         7.51\n\n\nThe following plot shows clear differences in stop frequency across hours of the day. Traffic stops increase substantially during daylight hours and decline late at night. Racial groups follow broadly similar patterns, though some groups appear to have disproportionately more stops during certain hours.\n\nlibrary(tidyverse)\n\nggplot(hourly, aes(x = hour, y = n_stops, color = subject_race)) +\ngeom_line(size = 1) +\nlabs(\ntitle = \"Number of Traffic Stops by Hour and Race\",\nx = \"Hour of Day (0–23)\",\ny = \"Number of Stops\",\ncolor = \"Driver Race\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\nThe following figure illustrates how search likelihood varies across the day and across racial groups. Certain groups show consistently higher search rates than others, even during hours where the number of stops is low.\n\nggplot(hourly, aes(x = hour, y = pct_searched, color = subject_race)) +\ngeom_line(size = 1) +\nlabs(\ntitle = \"Search Rate by Hour and Driver Race\",\nx = \"Hour of Day (0–23)\",\ny = \"Percent of Stops That Resulted in a Search\",\ncolor = \"Driver Race\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\nThis analysis reveals that both stop frequency and search rates vary substantially across time of day and across racial groups. Stops are most common in daytime and early evening hours, but search rates do not always follow this pattern. Instead, some racial groups experience higher search rates consistently throughout the day.\nReferences: - Pierson, E., Simoiu, C., Overgoor, J., Corbett-Davies, S., Ramachandran, V., Phillips, C., Shroff, R., & Goel, S. (2020). A large-scale analysis of racial disparities in police stops across the United States. Nature Human Behaviour. https://www.nature.com/articles/s41562-020-0858-1\n\nStanford Open Policing Project. (n.d.). Data portal. https://openpolicing.stanford.edu/data/"
  },
  {
    "objectID": "sf_rents.html",
    "href": "sf_rents.html",
    "title": "Bay Area Rental Prices",
    "section": "",
    "text": "This analysis explores rental listing prices across San Francisco Bay Area counties using publicly available Craigslist housing listings. The dataset includes rental prices, locations, and listing details over 18 years (2000–2018). The goal of this page is to provide a clear visualization of rental price distributions across counties in the Bay Area."
  },
  {
    "objectID": "sf_rents.html#introduction",
    "href": "sf_rents.html#introduction",
    "title": "Bay Area Rental Prices",
    "section": "",
    "text": "This analysis explores rental listing prices across San Francisco Bay Area counties using publicly available Craigslist housing listings. The dataset includes rental prices, locations, and listing details over 18 years (2000–2018). The goal of this page is to provide a clear visualization of rental price distributions across counties in the Bay Area."
  },
  {
    "objectID": "sf_rents.html#load-packages-and-data",
    "href": "sf_rents.html#load-packages-and-data",
    "title": "Bay Area Rental Prices",
    "section": "Load Packages and Data",
    "text": "Load Packages and Data\n\nlibrary(tidyverse)\n\n# Load TidyTuesday dataset for 2022-07-05\ntuesdata &lt;- tidytuesdayR::tt_load('2022-07-05')\nrent &lt;- tuesdata$rent"
  },
  {
    "objectID": "sf_rents.html#data-display",
    "href": "sf_rents.html#data-display",
    "title": "Bay Area Rental Prices",
    "section": "Data Display",
    "text": "Data Display\nBefore plotting, we first inspect the structure and distribution of the dataset.\n\nrent |&gt;\n  count(county, sort = TRUE)\n\n# A tibble: 11 × 2\n   county            n\n   &lt;chr&gt;         &lt;int&gt;\n 1 san francisco 55730\n 2 santa clara   41023\n 3 alameda       25630\n 4 san mateo     25238\n 5 contra costa  13605\n 6 sonoma        12422\n 7 marin         11237\n 8 santa cruz     8590\n 9 solano         3742\n10 napa           2185\n11 &lt;NA&gt;           1394\n\n\nThis helps us understand which countries have more rental listings represented in the dataset.\n\nrent |&gt;\n  summarise(\n    min_price = min(price, na.rm = TRUE),\n    median_price = median(price, na.rm = TRUE),\n    max_price = max(price, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  min_price median_price max_price\n      &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1       220         1800     40000\n\n\nThis gives a quick overview of price ranges before visualizing county-level differences."
  },
  {
    "objectID": "sf_rents.html#visualization",
    "href": "sf_rents.html#visualization",
    "title": "Bay Area Rental Prices",
    "section": "Visualization",
    "text": "Visualization\n\nggplot(rent, aes(x = price)) +\n  geom_boxplot() +\n  facet_wrap(\"county\") +\n  labs(title = \"Prices of Rentals in Different San Francisco Counties\", x = \"Price(USD)\") +\n  theme_minimal()\n\n\n\n\nDistribution of Bay Area rental prices across counties."
  },
  {
    "objectID": "sf_rents.html#interpretation",
    "href": "sf_rents.html#interpretation",
    "title": "Bay Area Rental Prices",
    "section": "Interpretation",
    "text": "Interpretation\nThe boxplots reveal clear variation in rental prices across Bay Area counties. Counties such as San Francisco and San Mateo display substantially higher median rental prices and larger spreads. Meanwhile, counties like Solano or Contra Costa show lower and more concentrated rental prices."
  },
  {
    "objectID": "sf_rents.html#references",
    "href": "sf_rents.html#references",
    "title": "Bay Area Rental Prices",
    "section": "References",
    "text": "References\nPennington, K. (2018). Bay Area Craigslist Rental Housing Posts, 2000–2018.\nhttps://github.com/katepennington/historic_bay_area_craigslist_housing_posts/blob/master/clean_2000_2018.csv.zip\nTidyTuesday / rfordatascience. (2022). TidyTuesday: San Francisco Rent (2022-07-05).\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2022/2022-07-05"
  },
  {
    "objectID": "obama_tweets.html",
    "href": "obama_tweets.html",
    "title": "Obama Tweets",
    "section": "",
    "text": "This analysis uses archived tweets from Barrack Obama’s Twitter page to explore two aspects of the former president’s communication on Twitter. First, the hashtags he used most frequently, and second, his use of collective versus individual pronouns. Tweets are taken from the publicly released Obama Administration social media archive, which includes all tweets posted by @POTUS (Obama) during his presidency. The dataset provides a useful lens into how he framed political messaging.\n\nlibrary(tidyverse)\n\nobama_tweets &lt;- \n  read_csv(unz(\"data/POTUS111716.zip\",\n               \"tweets.csv\")) |&gt;\n  select(text, timestamp) |&gt;\n  \n  # extract hashtags\n  mutate(hashtags = str_extract_all(text,\n                                    \"(?&lt;=#)\\\\w+\")) |&gt;\n  \n  # clean text and remove URLs/usernames\n  mutate(text_clean = str_replace_all(text,\n                                      \"https?://\\\\S+|@\\\\w+\", \n                                      \"\"), \n         text_clean = str_to_lower(text_clean)) |&gt; \n  \n  # count collective and individual pronouns\n  mutate(collective_count = str_count(text_clean, \n                                      \"\\\\b(we|us|our|ours|we're|we've)\\\\b\"),\n         individual_count = str_count(text_clean, \n                                      \"\\\\b(i|me|my|mine|i've|i'm)\\\\b\"))"
  },
  {
    "objectID": "obama_tweets.html#introduction",
    "href": "obama_tweets.html#introduction",
    "title": "Obama Tweets",
    "section": "",
    "text": "This analysis uses archived tweets from Barrack Obama’s Twitter page to explore two aspects of the former president’s communication on Twitter. First, the hashtags he used most frequently, and second, his use of collective versus individual pronouns. Tweets are taken from the publicly released Obama Administration social media archive, which includes all tweets posted by @POTUS (Obama) during his presidency. The dataset provides a useful lens into how he framed political messaging.\n\nlibrary(tidyverse)\n\nobama_tweets &lt;- \n  read_csv(unz(\"data/POTUS111716.zip\",\n               \"tweets.csv\")) |&gt;\n  select(text, timestamp) |&gt;\n  \n  # extract hashtags\n  mutate(hashtags = str_extract_all(text,\n                                    \"(?&lt;=#)\\\\w+\")) |&gt;\n  \n  # clean text and remove URLs/usernames\n  mutate(text_clean = str_replace_all(text,\n                                      \"https?://\\\\S+|@\\\\w+\", \n                                      \"\"), \n         text_clean = str_to_lower(text_clean)) |&gt; \n  \n  # count collective and individual pronouns\n  mutate(collective_count = str_count(text_clean, \n                                      \"\\\\b(we|us|our|ours|we're|we've)\\\\b\"),\n         individual_count = str_count(text_clean, \n                                      \"\\\\b(i|me|my|mine|i've|i'm)\\\\b\"))"
  },
  {
    "objectID": "obama_tweets.html#most-common-hashtags",
    "href": "obama_tweets.html#most-common-hashtags",
    "title": "Obama Tweets",
    "section": "Most Common Hashtags",
    "text": "Most Common Hashtags\nFirst, we must extract and count all of his hashtags.\n\nobama_hashtags &lt;- \n  obama_tweets |&gt; \n  select(hashtags) |&gt; \n  unnest(hashtags) |&gt; \n  group_by(hashtags) |&gt; \n  summarize(count = n()) |&gt; \n  arrange(desc(count)) |&gt; \n  head(5)\n\nThen, we can visualize the data.\n\nggplot(obama_hashtags, \n       aes(x = hashtags, \n           y = count, \n           fill = hashtags)) +\n  geom_col(show.legend = FALSE) +\n  labs(title = \"Frequency of Obama's Top Five Most Used Twitter Hashtags\", \n       x = \"Hashtag\", \n       y = \"Frequency\")\n\n\n\n\nObama’s five most frequently used hashtags.\n\n\n\n\nThe plot reveals which issues he emphasized publicly and illustrates some of the ways that the former president used Twitter to engage with the general public."
  },
  {
    "objectID": "obama_tweets.html#collective-vs.-individual-pronoun-usage",
    "href": "obama_tweets.html#collective-vs.-individual-pronoun-usage",
    "title": "Obama Tweets",
    "section": "Collective vs. Individual Pronoun Usage",
    "text": "Collective vs. Individual Pronoun Usage\nFirst, we must get the totals for each type of pronoun.\n\ntotal_pronouns &lt;- obama_tweets |&gt;\n  summarise(\n    collective_total = sum(collective_count),\n    individual_total = sum(individual_count)\n  ) |&gt;\n  pivot_longer(cols = everything(), names_to = \"pronoun_type\", values_to = \"total\")\n\nThen, we can visualize the data.\n\nggplot(total_pronouns, aes(x = pronoun_type, y = total, fill = pronoun_type)) +\n  geom_col(show.legend = FALSE) +\n  labs(\n    title = \"Total Usage of Collective vs. Individual Pronouns\",\n    x = \"Pronoun Type\",\n    y = \"Total Count\"\n  ) +\n  theme_minimal()\n\n\n\n\nComparison of collective vs. individual pronoun usage in Obama’s tweets.\n\n\n\n\nThe plot shows how Obama uses collective pronouns much more often than individual ones, and gives us insight into how Obama purposefully focused his tweets on unity and shared identity rather than on himself."
  },
  {
    "objectID": "obama_tweets.html#references",
    "href": "obama_tweets.html#references",
    "title": "Obama Tweets",
    "section": "References",
    "text": "References\nNational Archives and Records Administration. (n.d.). Obama White House Social Media Archive: Tweets.\nRetrieved from the Barack Obama Presidential Library:\nhttps://www.obamalibrary.gov/research/obama-white-house-social-media-archive"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Colby Cooley",
    "section": "",
    "text": "Hi there! I’m Colby. I am a student at Pomona College, and I’m interested in studying data science, economics, and math. I also play for the Pomona-Pitzer football team and love hanging out with friends in my spare time. This website is a place for me to display a variety of different projects that I’ve worked on. Poke around to learn more!"
  },
  {
    "objectID": "freedom.html",
    "href": "freedom.html",
    "title": "Global Freedom Indicators",
    "section": "",
    "text": "This analysis explores worldwide patterns in civil liberties and political rights using data from Freedom House and republished through TidyTuesday. The dataset provides annual scores on political rights and civil liberties, two important measures of democratic conditions, each on a scale from 1(most free) to 7(least free). Countries are also categorized as Free, Partly Free, or Not Free. The goal of this analysis is to visualize how these indicators relate to each other and how freedom status clusters across countries."
  },
  {
    "objectID": "freedom.html#introduction",
    "href": "freedom.html#introduction",
    "title": "Global Freedom Indicators",
    "section": "",
    "text": "This analysis explores worldwide patterns in civil liberties and political rights using data from Freedom House and republished through TidyTuesday. The dataset provides annual scores on political rights and civil liberties, two important measures of democratic conditions, each on a scale from 1(most free) to 7(least free). Countries are also categorized as Free, Partly Free, or Not Free. The goal of this analysis is to visualize how these indicators relate to each other and how freedom status clusters across countries."
  },
  {
    "objectID": "freedom.html#load-packages-and-data",
    "href": "freedom.html#load-packages-and-data",
    "title": "Global Freedom Indicators",
    "section": "Load Packages and Data",
    "text": "Load Packages and Data\n\nlibrary(tidyverse)\n\n# Load 2022 TidyTuesday dataset\ntuesdata &lt;- tidytuesdayR::tt_load('2022-02-22')\nfreedom &lt;- tuesdata$freedom\n\n# Clean Status variable for readability\nfreedom &lt;- freedom |&gt; \n  mutate(status_full = case_when(Status == \"F\"  ~ \"Free\", Status == \"PF\" ~ \"Partly Free\", Status == \"NF\" ~ \"Not Free\", TRUE ~ Status))"
  },
  {
    "objectID": "freedom.html#data-display",
    "href": "freedom.html#data-display",
    "title": "Global Freedom Indicators",
    "section": "Data Display",
    "text": "Data Display\nBefore visualizing the relationship between PR and CL, it’s helpful to see the distribution of freedom categories. This shows how many countries fall into each category in the 2022 dataset.\n\nfreedom |&gt;\n  count(status_full)\n\n# A tibble: 3 × 2\n  status_full     n\n  &lt;chr&gt;       &lt;int&gt;\n1 Free         2219\n2 Not Free     1257\n3 Partly Free  1503"
  },
  {
    "objectID": "freedom.html#visualization",
    "href": "freedom.html#visualization",
    "title": "Global Freedom Indicators",
    "section": "Visualization",
    "text": "Visualization\n\nggplot(freedom, aes(x = CL, y = PR, color = status_full)) +\n  geom_jitter(width = 0.2, height = 0.2, alpha = 0.7) +\n  scale_color_manual(values = c(\"Free\" = \"seagreen3\", \"Partly Free\" = \"goldenrod\", \"Not Free\" = \"firebrick\")) +\n  labs(title = \"Political Rights v.s. Civil Liberties Showing Freedom Status\", x = \"Civil Liberties Score(1 = most, 7 = least)\", y = \"Political Rights Score(1 = most, 7 = least)\", color = \"Status\") +\n  theme_minimal()\n\n\n\n\nCivil liberties and political rights across world countries, colored by overall Freedom House status."
  },
  {
    "objectID": "freedom.html#interpretation",
    "href": "freedom.html#interpretation",
    "title": "Global Freedom Indicators",
    "section": "Interpretation",
    "text": "Interpretation\nMost countries classified as Free are clustered in the lower-left of the plot, with both low political rights and civil liberties scores(indicating greater freedom). Not Free countries cluster in the upper-right, reflecting more restrictive conditions. Partly Free countries span the middle, showing a wide range of governance environments. This pattern visually reinforces Freedom House’s classification scheme, with PR and CL scores tending to move together and align with the overall freedom rating."
  },
  {
    "objectID": "freedom.html#references",
    "href": "freedom.html#references",
    "title": "Global Freedom Indicators",
    "section": "References",
    "text": "References\nFreedom House. (2022). Freedom in the World 2022 Dataset.\nhttps://freedomhouse.org/report/freedom-world\nTidyTuesday / rfordatascience. (2022). TidyTuesday: Freedom in the World (2022-02-22).\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2022/2022-02-22"
  },
  {
    "objectID": "movie_genre.html",
    "href": "movie_genre.html",
    "title": "Movie Genre and IMDb Ratings",
    "section": "",
    "text": "Movie ratings are widely used to evaluate films. People often claim that some genres are “better” than others based on audience scores. However, this perception might just stem from random variation. Understanding whether genre truly influences ratings could help studios and critics separate taste patterns from statistical noise. By examining a dataset of movies and their ratings, we can statistically test whether genre is associated with IMDb ratings in a broader population sense. We will try to see if the observed differences in the ratings across genres of a sample are likely to occur by chance. A permutation test is perfect for this because it will simply test whether the association between genre and rating is stronger than we would expect if genres had no effect.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "movie_genre.html#introduction",
    "href": "movie_genre.html#introduction",
    "title": "Movie Genre and IMDb Ratings",
    "section": "",
    "text": "Movie ratings are widely used to evaluate films. People often claim that some genres are “better” than others based on audience scores. However, this perception might just stem from random variation. Understanding whether genre truly influences ratings could help studios and critics separate taste patterns from statistical noise. By examining a dataset of movies and their ratings, we can statistically test whether genre is associated with IMDb ratings in a broader population sense. We will try to see if the observed differences in the ratings across genres of a sample are likely to occur by chance. A permutation test is perfect for this because it will simply test whether the association between genre and rating is stronger than we would expect if genres had no effect.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "movie_genre.html#import-and-wrangle-data",
    "href": "movie_genre.html#import-and-wrangle-data",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Import and Wrangle Data",
    "text": "Import and Wrangle Data\nThe following dataset contains information on the genre and rating of 10,000 different movies in the IMDb database. We are specifically interested in these variables because we want to observe the relationship between them.\n\n# Read data\nimdb &lt;- read_csv(\n  \"data/imdb-movies-dataset.csv\"\n) |&gt;\n  \n  # Extract a primary genre to reduce sparsity\n  mutate(Genre2 = str_extract(Genre, \"^[A-z-]+\")) |&gt;\n  \n  # Keep only the variables needed for this analysis\n  select(Title, Genre2, Rating)"
  },
  {
    "objectID": "movie_genre.html#visualizing-ratings-by-genre",
    "href": "movie_genre.html#visualizing-ratings-by-genre",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Visualizing Ratings by Genre",
    "text": "Visualizing Ratings by Genre\nYou can see how some genres have higher median ratings than others and vice versa.\nThe following plot shows the differences in the distributions of different genre’s movie ratings based on this data.\n\nggplot(imdb, aes(x = Genre2, y = Rating, fill = Genre2)) +\n  geom_boxplot() +\n  labs(title = \"Rating Distribution of Movies in Different Genres\", x = \"Genre\", fill = \"Genre\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nRating distributions by primary genre (boxplots). Each facet displays the distribution of IMDb ratings for the listed genre."
  },
  {
    "objectID": "movie_genre.html#hypotheses",
    "href": "movie_genre.html#hypotheses",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Hypotheses",
    "text": "Hypotheses\nH₀ (null): The model that generates movie ratings is the same for all genres (genre has no effect). Any observed differences across genres are due to chance.\nHₐ (alternative): The model that generates ratings differs by genre; therefore, some genres have systematically different mean ratings in the population."
  },
  {
    "objectID": "movie_genre.html#test-statistic",
    "href": "movie_genre.html#test-statistic",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Test Statistic",
    "text": "Test Statistic\nWe use an ANOVA-style test statistic that weights squared deviations of each genre mean from the overall mean by genre sample size:\n\\[\nT = \\sum_i n_i (\\bar{x}_i - \\bar{x})^2\n\\]\nwhere \\(n_i\\) is the number of movies in genre \\(i\\), \\(\\bar{x}_i\\) the genre mean, and \\(\\bar{x}\\) the overall mean. A larger \\(T\\) indicates larger between-genre differences relative to the overall mean.\n\nimdb |&gt; summarize(avg_rating = mean(Rating, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  avg_rating\n       &lt;dbl&gt;\n1       6.44\n\nmean_rating &lt;- 6.43861\nimdb |&gt;\n  group_by(Genre2) |&gt;\n  summarize(ni = n(), xi = mean(Rating, na.rm = TRUE)) |&gt;\n  summarize(stat = sum(ni * (xi - mean_rating)^2, na.rm = TRUE))\n\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1 1086.\n\nobs_stat &lt;- 1085.533"
  },
  {
    "objectID": "movie_genre.html#permutation-test",
    "href": "movie_genre.html#permutation-test",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Permutation Test",
    "text": "Permutation Test\nNow we need a function that can simulate/permute this calculation while assuming genres are randomly assigned to movies(the null hypothesis(Ho)). In other words, each simulation randomly reassigns genres to movies to break any real association between genre and rating.\n\nimdb_sim &lt;- function(x) {\n  sim_value &lt;- imdb |&gt;\n    mutate(Genre2 = sample(Genre2, n(), replace = FALSE)) |&gt;\n    group_by(Genre2) |&gt;\n    summarize(ni = n(), xi = mean(Rating, na.rm = TRUE)) |&gt;\n    summarize(stat = sum(ni * (xi - mean_rating)^2, na.rm = TRUE)) |&gt;\n    pull(stat)\n  return(sim_value)\n}\n\nThen we can use mapping to run this simulation/permutation many times so that we can be more confident in the results.\n\nset.seed(47)\nnull_stats &lt;- map_dbl(c(1:1000), ~imdb_sim(.x))\n\nnull_df &lt;- data.frame(stat = null_stats)"
  },
  {
    "objectID": "movie_genre.html#null-distribution-vs-observed-statistic",
    "href": "movie_genre.html#null-distribution-vs-observed-statistic",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Null Distribution vs Observed Statistic",
    "text": "Null Distribution vs Observed Statistic\nThe following plot shows the distribution of the one thousand simulated/permuted values as well as a vertical line at the observed statistic.\n\nggplot(null_df, aes(x = stat)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  geom_vline(xintercept = obs_stat, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\"text\", x = obs_stat, y = 50, label = \"Observed Statistic\", \n           color = \"red\", angle = 90, vjust = -0.5, hjust = 1.2) +\n  labs(\n    title = \"Null Distribution of Permuted Statistics\",\n    x = \"Simulated Statistic\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n\n\n\nNull distribution of the permuted test statistic (1000 permutations). The red dashed line shows the observed statistic from the real data."
  },
  {
    "objectID": "movie_genre.html#conclusion",
    "href": "movie_genre.html#conclusion",
    "title": "Movie Genre and IMDb Ratings",
    "section": "Conclusion",
    "text": "Conclusion\nAs you can see, not a single one of the thousand permuted statistics even came close to being at least as extreme as the observed statistic, meaning the p-value for this test is 0. This means that we have very strong evidence supporting the alternative hypthesis(Ha) that movie ratings differ by genre and that some genres consistently receive higher or lower ratings. This conclusion is about the population model (i.e., whether genre is associated with ratings in general) because the permutation test simulates the null model of no genre effect and compares the observed statistic to that null."
  },
  {
    "objectID": "movie_genre.html#references",
    "href": "movie_genre.html#references",
    "title": "Movie Genre and IMDb Ratings",
    "section": "References",
    "text": "References\nBarthwal, Aman. IMDb Movies Data. Kaggle, 2024.\nhttps://www.kaggle.com/datasets/amanbarthwal/imdb-movies-data"
  },
  {
    "objectID": "presentation.html#introduction",
    "href": "presentation.html#introduction",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Introduction",
    "text": "Introduction\n\nIs there an association between a movie’s genre and its IMDb rating?\nWe can statistically test this by examining a dataset of some movies and their ratings\nWe will try to see if the observed differences in the ratings across genres of a sample are likely to occur by chance\nA permutation test is perfect for this because it will simply test whether the association between genre and rating is stronger than we would expect if genres had no effect"
  },
  {
    "objectID": "presentation.html#import-and-wrangle-data",
    "href": "presentation.html#import-and-wrangle-data",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Import and Wrangle Data",
    "text": "Import and Wrangle Data\nThe following dataset contains information on the genre and rating of 10,000 different movies in the IMDb database:\n\nlibrary(tidyverse)\n\n# Read data\nimdb &lt;- read_csv(\n  \"data/imdb-movies-dataset.csv\"\n) |&gt;\n  \n  # Extract a primary genre to reduce sparsity\n  mutate(Genre2 = str_extract(Genre, \"^[A-z-]+\")) |&gt;\n  \n  # Keep only the variables needed for this analysis\n  select(Title, Genre2, Rating)"
  },
  {
    "objectID": "presentation.html#visualizing-ratings-by-genre",
    "href": "presentation.html#visualizing-ratings-by-genre",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Visualizing Ratings by Genre",
    "text": "Visualizing Ratings by Genre\nThe following plot shows the differences in the distributions of different genre’s movie ratings based on this data:\n\nggplot(imdb, aes(x = Genre2, y = Rating, fill = Genre2)) +\n  geom_boxplot() +\n  labs(title = \"Rating Distribution of Movies in Different Genres\", x = \"Genre\", fill = \"Genre\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nRating distributions by primary genre (boxplots). Each facet displays the distribution of IMDb ratings for the listed genre."
  },
  {
    "objectID": "presentation.html#hypotheses",
    "href": "presentation.html#hypotheses",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Hypotheses",
    "text": "Hypotheses\nH₀ (null): The model that generates movie ratings is the same for all genres (genre has no effect). Any observed differences across genres are due to chance.\nHₐ (alternative): The model that generates ratings differs by genre; therefore, some genres have systematically different mean ratings in the population."
  },
  {
    "objectID": "presentation.html#test-statistic",
    "href": "presentation.html#test-statistic",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Test Statistic",
    "text": "Test Statistic\nWe use an ANOVA-style test statistic that weights squared deviations of each genre mean from the overall mean by genre sample size: \\[\nT = \\sum_i n_i (\\bar{x}_i - \\bar{x})^2\n\\] where \\(n_i\\) is the number of movies in genre \\(i\\), \\(\\bar{x}_i\\) the genre mean, and \\(\\bar{x}\\) the overall mean.\n\nimdb |&gt; summarize(avg_rating = mean(Rating, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  avg_rating\n       &lt;dbl&gt;\n1       6.44\n\nmean_rating &lt;- 6.43861\nimdb |&gt;\n  group_by(Genre2) |&gt;\n  summarize(ni = n(), xi = mean(Rating, na.rm = TRUE)) |&gt;\n  summarize(stat = sum(ni * (xi - mean_rating)^2, na.rm = TRUE))\n\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1 1086.\n\nobs_stat &lt;- 1085.533"
  },
  {
    "objectID": "presentation.html#permutation-test",
    "href": "presentation.html#permutation-test",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Permutation Test",
    "text": "Permutation Test\nNow we need a function that can simulate/permute this calculation while assuming genres are randomly assigned to movies(the null hypothesis(Ho)).\n\nimdb_sim &lt;- function(x) {\n  sim_value &lt;- imdb |&gt;\n    mutate(Genre2 = sample(Genre2, n(), replace = FALSE)) |&gt;\n    group_by(Genre2) |&gt;\n    summarize(ni = n(), xi = mean(Rating, na.rm = TRUE)) |&gt;\n    summarize(stat = sum(ni * (xi - mean_rating)^2, na.rm = TRUE)) |&gt;\n    pull(stat)\n  return(sim_value)\n}\n\nThen we can use mapping to run this simulation/permutation many times so that we can be more confident in the results.\n\nset.seed(47)\nnull_stats &lt;- map_dbl(c(1:1000), ~imdb_sim(.x))\n\nnull_df &lt;- data.frame(stat = null_stats)"
  },
  {
    "objectID": "presentation.html#null-distribution-vs-observed-statistic",
    "href": "presentation.html#null-distribution-vs-observed-statistic",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Null Distribution vs Observed Statistic",
    "text": "Null Distribution vs Observed Statistic\nThe following plot shows the distribution of the one-thousand simulated/permuted values as well as a vertical line at the observed statistic:\n\nggplot(null_df, aes(x = stat)) +\n  geom_histogram(binwidth = 1, color = \"black\") +\n  geom_vline(xintercept = obs_stat, color = \"red\") +\n  annotate(\"text\", x = obs_stat, y = 50, label = \"Observed Statistic\", \n           color = \"red\", angle = 90, vjust = -0.5, hjust = 1) +\n  labs(\n    title = \"Null Distribution of Permuted Statistics\",\n    x = \"Simulated Statistic\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n\nNull distribution of the permuted test statistic (1000 permutations). The red line shows the observed statistic from the real data."
  },
  {
    "objectID": "presentation.html#conclusion",
    "href": "presentation.html#conclusion",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "Conclusion",
    "text": "Conclusion\n\nNone of the thousand permuted statistics came close to being at least as extreme as the observed statistic, meaning the p-value for this test is 0\nWe have very strong evidence supporting the alternative hypthesis(Ha)\nThis conclusion is about the population model (i.e., whether genre is associated with ratings in general)"
  },
  {
    "objectID": "presentation.html#references",
    "href": "presentation.html#references",
    "title": "Do Movie Genres Differ in Their IMDb Ratings?",
    "section": "References",
    "text": "References\nBarthwal, Aman. IMDb Movies Data. Kaggle, 2024.\nhttps://www.kaggle.com/datasets/amanbarthwal/imdb-movies-data"
  },
  {
    "objectID": "taxi.html",
    "href": "taxi.html",
    "title": "NYC Taxi",
    "section": "",
    "text": "Sources\nGoodin, Dan. “Poorly Anonymized Logs Reveal NYC Cab Drivers’ Detailed Whereabouts.” Ars Technica, 27 June 2014. https://arstechnica.com/information-technology/2014/06/poorly-anonymized-logs-reveal-nyc-cab-drivers-detailed-whereabouts/.\nTockar, Anthony. “Riding with the Stars: Passenger Privacy in the NYC Taxicab Dataset.” Vet Scholar Journal Club, Kansas State University, 2024. PDF file. https://www.vet.k-state.edu/research/student-opportunities/vet-scholar/calendar/pdf/2024-journal-club-docs/session-1/Riding%20with%20the%20Stars_%20Passenger%20Privacy%20in%20the%20NYC%20Taxicab%20Dataset.pdf\n\n\nIntro\nIn 2014, as part of an open-data initiative to support transparency, entrepreneurship, and urban planning, New York City’s Taxi and Limousine Commission(TLC) publicly released data on 173 million taxi rides. The dataset included pick-up and drop-off times, locations, fares, and anonymized driver medallion numbers. Soon after, however, researchers and journalists discovered that the data could be easily de-anonymized to reveal the identities and movements of drivers and even passengers(Goodin; Tockar). The release raised deep questions about what counts as anonymized data, who decides to share it, and who bears the consequences when it’s misused.\nThe dataset was released as a structured CSV with variables to record medallion number(hashed), trip start/end timestamps, GPS coordinates, fares, and tips. But, as it turned out, the hashing used to anonymize medallion numbers was weak and could be reversed with a simple MD5 hash lookup(Goodin). Data scientists and journalists were able to re-identify by cross-referencing ride timestamps and locations with Instagram posts, paparazzi photos, and celebrity schedules(Tockar). This technique is a classic data science method used to connect separate datasets based on overlapping attributes. The case thus shows how the same analytical tools that can produce insights can also compromise privacy.\n\n\nWhat is the permission structure for using the data? Was it followed?\nThe data came from drivers and passengers and was collected under regulatory requirements for fare reporting. It was not intended for public research. Neither group was asked for consent to release detailed trip-level information(Goodin; Tockar). The NYC TLC justified release under an open data initiative, but this was institutional consent, not individual consent. It raises the question of if institutions can consent on behalf of individuals.\n\n\nIs the data identifiable? In what way? Is the data sufficiently anonymized or old to be free of ethical concerns? Is anonymity guaranteed?\nThe TLC claimed that removing names and hashing medallions ensured privacy, however, the MD5 hashes were reversible and pickup/drop-off times plus coordinates uniquely identified specific trips(Goodin). Anthony Tockar showed that a handful of coordinates could reveal celebrity movements, such as when Bradley Cooper and Jessica Alba took cabs(Tockar). The case demonstrates that anonymization is fragile when datasets are detailed but patchy. Even when they don’t have names, identity can be inferred. This links to a broader principle, the mosaic effect, which is when many harmless pieces of data combine to form identifiable pictures(Tockar).\n\n\nWas the data made publicly available? Why? How? On what platform?\nThe dataset was released on NYC’s Open Data portal for transparency and research innovation, which could potentially benefit entrepreneurs, journalists, or app developers(Goodin; Tockar). But the drivers and passengers, on the other hand, bore the privacy risk without reaping any of those benefits. This reflects a power imbalance where city officials and data scientists control data circulation. Individuals become data points in systems without being able to opt out. For example, drivers’ income and working patterns could be reconstructed, thereby invading financial privacy(Tockar).\n\n\nWhat was the consent structure for recruiting participants? Was informed consent possible? Can you provide informed consent for applications that are yet foreseen? Is the data being used in unintended ways to the original study?\nThe data were originally collected for regulatory compliance, not for open public distribution(Goodin; Tockar). No one foresaw the ways the dataset could be combined with other sources for re-identification or surveillance(Tockar). It raises the issue of whether or not we can we give informed consent for uses that haven’t been invented yet. It also demonstrates the need to anticipate future analytical capabilities(Tockar).\n\n\nConclusion\nThe NYC Taxi dataset illustrates how data science, even with good intentions such as open data or innovation, can reproduce structural power imbalances and harm those with least control over data circulation(Goodin; Tockar). Drivers lost privacy and were economically exposed, while passengers could now be tracked(Tockar). Meanwhile, data scientists and tech companies profited from free data(Goodin). The ethical violations occurred largely in the service of efficiency, transparency, and potential profit, not necessarily out of malice. This shows how claims of public benefit can obscure real harms(Tockar). The work was done by city data scientists, not affected individuals(Goodin). Researchers, startups, and journalists benefited. Taxi drivers and ordinary riders were harmed or neglected(Tockar)."
  }
]